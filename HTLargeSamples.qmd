---
title: "Hypothesis Testing: Large Samples"
format: 
  live-html:
    theme:
      light: [lux, theme-light.scss]
      dark: [superhero, theme-dark.scss]
engine: knitr
toc: true
webr:
  packages:
    - palmerpenguins 
    - dplyr
    - ggplot2
    - purrr
---

{{< include _extensions/r-wasm/live/_knitr.qmd >}}

Hypothesis testing with large samples ($n \geq 30$) benefits from the Central Limit Theorem, which ensures that sample means are approximately normally distributed. This allows the use of $t$-tests even when the underlying population distribution is unknown. A well-defined 8-step framework aids in systematically evaluating hypotheses, balancing statistical rigor with practical decision-making.



## Motivating Case: Public Health Crisis Response

Consider a public health application involving NYC’s historical temperature data. Using the `airquality` dataset (n = 153), we test whether the mean temperature exceeds 77°F. The one-sided $t$-test returns a test statistic of $t = 1.1531$ and a p-value of 0.1253. Since this p-value exceeds the typical $\alpha = 0.05$ threshold, we **fail to reject** the null hypothesis. Despite the observed mean being $77.88^\circ$F, the evidence is insufficient to conclude that temperatures are significantly above 77°F. 



```{webr}
data(airquality)
t.test(airquality$Temp, mu = 77, alternative = "greater", conf.level = 0.95)
```


### Poultry Farming (ChickWeight)

In contrast, consider the `ChickWeight` dataset where we examine whether chicks on Diet 1 have a mean weight different from 100g. With n = 220, a two-sided $t$-test yields $t = 0.6926$ and a p-value of 0.4893. The observed mean weight is 102.65g, but again the large p-value indicates **no significant difference** from the hypothesized mean. The 95% confidence interval (95.12g, 110.17g) includes 100g, reinforcing that any deviation could easily be due to sampling variability.


```{webr}
diet1 <- subset(ChickWeight, Diet == 1)$weight
t.test(diet1, mu = 100, alternative = "two.sided")
```


These examples highlight that even with large samples, statistical significance depends on both effect size and variability—not merely sample size. Proper interpretation ensures sound, data-driven decisions.

