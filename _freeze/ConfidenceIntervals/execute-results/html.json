{
  "hash": "40a6aef339fa6dee390cc3596ca24a07",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Confidence Intervals\"\nformat: live-html\nengine: knitr\ntoc: true\nwebr:\n  packages:\n    - palmerpenguins \n    - dplyr\n    - ggplot2\n    - purrr\n---\n\n::: {.cell}\n\n:::\n\n\n**Confidence intervals** estimate unknown population parameters (e.g., a mean $\\mu$ or proportion) using sample data. While a **point estimator** like the sample mean $\\bar{X}$ provides a single-value estimate, it lacks a measure of reliability. An **interval estimator** (confidence interval) addresses this by producing a range of values with an associated **confidence level** (e.g., 95%). This confidence level reflects the long-run success rate of the method: *if we repeatedly sampled the population and constructed intervals, 95% of those intervals would contain the true parameter*. This \"repeated sampling\" interpretation emphasizes that the confidence level describes the *method’s reliability*, not the probability that a single interval contains the parameter.\n\nTo illustrate, let’s simulate 95% confidence intervals for a population mean $\\mu = 50$ using R. We’ll generate 50 samples (each with $n=30$ observations) from a normal distribution, compute their confidence intervals, and visualize results. Plotting these intervals shows most (≈95%) capture $\\mu$, while a few miss it – mirroring the confidence level’s meaning. The proportion of intervals containing $\\mu$ will typically hover near 0.95, with deviations due to random sampling.\n\n::: {.cell}\n```{webr}\n#| echo: false\n# Simulate repeated sampling and plot CIs\nset.seed(123)\ntrue_mean <- 50\ncis <- map_df(1:100, ~{\n  sample_data <- rnorm(30, true_mean, 10)\n  t_test <- t.test(sample_data)\n  tibble(\n    sample = .x,\n    lower = t_test$conf.int[1],\n    upper = t_test$conf.int[2],\n    estimate = mean(sample_data),\n    contains_mu = between(true_mean, lower, upper)\n  )\n})\n\nggplot(cis, aes(x = sample, y = estimate, \n                color = contains_mu, ymin = lower, ymax = upper)) +\n  geom_point() + \n  geom_errorbar() +\n  geom_hline(yintercept = true_mean, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"95% Confidence Intervals from 100 Samples\",\n       subtitle = paste(\"Proportion containing μ:\", \n                        round(mean(cis$contains_mu), 2))) +\n  scale_color_manual(\n    name = \"Contains μ?\",  \n    values = c(`TRUE` = \"gray30\", `FALSE` = \"red\")  \n  )\n```\n:::\n\n**Key insights**:  \n\n1. A 95% CI does *not* mean \"there’s a 95% chance $\\mu$ lies in this interval\" – $\\mu$ is fixed, and the interval either contains it or not.  \n2. Coverage depends on assumptions (e.g., normality via CLT for small $n$; less critical for $n \\geq 30$).  \n3. In practice, you only compute *one* interval, but its reliability is tied to the theoretical behavior of *many* intervals.  \n",
    "supporting": [
      "ConfidenceIntervals_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}